{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "16a88096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import numpy\n",
    "\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    \n",
    "    '''\n",
    "    I. \n",
    "    \n",
    "    Creates a matrix of y-dim by x=dim:  \n",
    "    \n",
    "    distances=numpy.zeros(y-dim, x-dim)\n",
    "    distances[y-coordinate][x-coordinate]. \n",
    "    '''\n",
    "    \n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1)) \n",
    "\n",
    "    '''\n",
    "    II. Creates numeric labels for matrix columns and rows.\n",
    "    '''\n",
    "    \n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "    \n",
    "        \n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    III.  \n",
    "    \n",
    "    Plots in zeros for characters that are identical, \n",
    "    where distances[1][1] representes the value for the first character of both tokens,  \n",
    "    distances[2][2] represents the value for the second character of both tokens, \n",
    "    distances[1][0] reoresents the score for the first character of token 1 compared to a non-existent token2, \n",
    "    etc.\n",
    "    \n",
    "    Iterates through each of the letters of the first token, and calculates LD score for all those letters combined \n",
    "    with only the first letter of the second token, and then repeats the same thing until \n",
    "    scores have been calculated for each of characters in the second token. \n",
    "    \n",
    "    '''\n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):                #If characters are the same, score is 0.\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            elif (token1[t1-1], token2[t2-1]) == ('p', 'd'):  #If characters meet our criteria, score is x.\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + .5\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + .5\n",
    "                else:\n",
    "                    distances[t1][t2] = c + .5\n",
    "            else:                                             #For all other characters, score is 1.\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "\n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    print((distances, len(token1), len(token2)))\n",
    "    return distances[len(token1)][len(token2)]\n",
    "                \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "eb678d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0. , 1. , 2. , 3. ],\n",
      "       [1. , 0.5, 1.5, 2.5],\n",
      "       [2. , 1.5, 0.5, 1.5],\n",
      "       [3. , 2.5, 1.5, 0.5]]), 3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDistanceDP('pig', 'dig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "b3c58fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0. , 1. , 2. , 3. ],\n",
      "       [1. , 0.5, 1.5, 2. ],\n",
      "       [2. , 1.5, 0.5, 1.5],\n",
      "       [3. , 2. , 1.5, 1. ]]), 3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDistanceDP('pop', 'dod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "9d1dc1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0. , 1. , 2. , 3. ],\n",
      "       [1. , 0.5, 1.5, 2. ],\n",
      "       [2. , 1.5, 1.5, 2.5],\n",
      "       [3. , 2. , 2.5, 2. ]]), 3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDistanceDP('pip', 'dod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "591366dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0., 1., 2., 3.],\n",
      "       [1., 1., 2., 3.],\n",
      "       [2., 2., 2., 3.],\n",
      "       [3., 3., 3., 3.]]), 3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDistanceDP('tig', 'dod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "201d7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import numpy\n",
    "\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = numpy.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    #printDistances(distances, len(token1), len(token2))\n",
    "    return distances[len(token1)][len(token2)]\n",
    "\n",
    "def LDScore(infile, outfile): \n",
    "\n",
    "    with open(infile, 'r', encoding='utf-8') as source, open(outfile, 'w', encoding='utf-8') as sink: \n",
    "        reader = csv.reader(source, delimiter = ',')\n",
    "        writer = csv.writer(sink, delimiter = '\\t')\n",
    "        count = 0\n",
    "        for line in reader: \n",
    "            ASRAns = line[0].rstrip()\n",
    "            ExpAns = line[1].rstrip()\n",
    "            LD = levenshteinDistanceDP(ASRAns, ExpAns)\n",
    "            writer.writerow((ASRAns, ExpAns, LD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ed93c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDScore('ASREs.IPA.txt', 'ASREs.LD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f10f335b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('beðo', 'deðo', 1.0): [(0, ('b', 'd'))], ('keðo', 'deðo', 1.0): [(0, ('k', 'd'))], ('peðo', 'deðo', 1.0): [(0, ('p', 'd'))], ('deɾo', 'deðo', 1.0): [(2, ('ɾ', 'ð'))], ('teto', 'deðo', 2.0): [(0, ('t', 'd')), (2, ('t', 'ð'))], ('bweno', 'deðo', 3.0): [(0, ('b', 'd')), (1, ('w', 'e')), (2, ('e', 'ð')), (3, ('n', 'o'))]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('ASREs.txt', encoding='utf-8', sep='\\t')\n",
    "df.columns = ['ASR Ans', 'Exp Ans', 'LD score']\n",
    "df_sorted = df.sort_values(by='LD score')\n",
    "\n",
    "\n",
    "\n",
    "characters = {}\n",
    "for ASR, Exp, LD in zip(df_sorted['ASR Ans'].head(6), df_sorted['Exp Ans'].head(6), df_sorted['LD score'].head(6)): \n",
    "    Chars = []\n",
    "    for ASRChar, ExpChar in enumerate(zip(ASR, Exp)):\n",
    "            Chars.append((ASRChar, ExpChar))\n",
    "        \n",
    "    characters[ASR, Exp, LD] = Chars\n",
    "\n",
    "different_phones = {}\n",
    "for k,v in characters.items(): \n",
    "    diff_phones = []\n",
    "    for item in v: \n",
    "        if item[1][0]!=item[1][1]:\n",
    "            diff_phones.append(item)\n",
    "    \n",
    "    different_phones[k] = diff_phones\n",
    "            \n",
    "\n",
    "print(different_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4baf9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "EsConFeatures = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "192689af",
   "metadata": {},
   "outputs": [],
   "source": [
    "EsConFeatures['n'] = set(('nasal', 'alveolar', 'voiced'))\n",
    "EsConFeatures['f'] = set(('fricative', 'labiodental', 'voiceless'))\n",
    "EsConFeatures['m'] = set(('nasal', 'bilabial', 'voiced'))\n",
    "EsConFeatures['b'] = set(('plosive', 'bilabial', 'voiceless'))\n",
    "EsConFeatures['ɾ'] = set(('tap', 'alveolar','voiced'))\n",
    "EsConFeatures['k'] = set(('plosive', 'velar', 'voiceless'))\n",
    "EsConFeatures['l'] = set(('lateral approximant', 'alveolar', 'voiced'))\n",
    "EsConFeatures['d'] = set(('plosive','alveolar','voiced'))\n",
    "EsConFeatures['v'] = set(('fricative', 'labiodental','voiceless'))\n",
    "EsConFeatures['p'] = set(('plosive', 'bilabial','voiced'))\n",
    "EsConFeatures['j'] = set(('approximant', 'palatal','voiced'))\n",
    "EsConFeatures['ð'] = set(('fricative', 'dental','voiced'))\n",
    "EsConFeatures['w'] = set(('approximant','bilabial','voiced'))\n",
    "EsConFeatures['ʃ'] = set(('fricative', 'post-alveolar','voiceless'))\n",
    "EsConFeatures['t'] = set(('plosive', 'alveolar', 'voiceless'))\n",
    "EsConFeatures['ɡ'] = set(('plosive', 'velar', 'voiced'))\n",
    "EsConFeatures['ŋ'] = set(('nasal', 'velar','voiced'))\n",
    "EsConFeatures['s'] = set(('fricative','alveolar', 'voiceless'))\n",
    "#EsConFeatures['d͡ʒ'] = set(('affricate', 'post-alveolar', 'voiced'))\n",
    "#EsConFeatures['t͡ʃ'] = set(('affricate', 'post-alveolar', 'voiceless'))\n",
    "EsConFeatures['β'] = set(('fricative' 'bilabial', 'voiced'))\n",
    "EsConFeatures['x'] = set(('fricative', 'velar', 'voiceless'))\n",
    "EsConFeatures['ɣ'] = set(('fricative', 'velar', 'voiced'))\n",
    "EsConFeatures['ʝ'] = set(('fricative', 'palatal', 'voiced'))\n",
    "EsConFeatures['ʎ'] = set(('lateral approximant', 'palatal', 'voiced'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a3655522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('beðo', 'deðo', 1.0) [(0, ('b', 'd'))]\n",
      "('keðo', 'deðo', 1.0) [(0, ('k', 'd'))]\n",
      "('peðo', 'deðo', 1.0) [(0, ('p', 'd'))]\n",
      "('deɾo', 'deðo', 1.0) [(2, ('ɾ', 'ð'))]\n",
      "('teto', 'deðo', 2.0) [(0, ('t', 'd')), (2, ('t', 'ð'))]\n",
      "('bweno', 'deðo', 3.0) [(0, ('b', 'd')), (1, ('w', 'e')), (2, ('e', 'ð')), (3, ('n', 'o'))]\n",
      "\n",
      "minimal_pairs: {('teto', 'deðo'), ('peðo', 'deðo')}\n",
      "TwoFeature_pairs: {('beðo', 'deðo'), ('keðo', 'deðo'), ('bweno', 'deðo')}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "minimal_pairs = set()\n",
    "TwoFeature_pairs = set()\n",
    "for k,v in different_phones.items(): \n",
    "    print(k,v)\n",
    "    for item in v: \n",
    "        ASRChar = item[1][0]\n",
    "        ExpChar = item[1][1]\n",
    "        position = item[0]\n",
    "        if position == 0:\n",
    "            if len(EsConFeatures[ASRChar]-EsConFeatures[ExpChar])==1: \n",
    "                minimal_pairs.add(\n",
    "                    (k[0], k[1])\n",
    "                )\n",
    "            if len(EsConFeatures[ASRChar]-EsConFeatures[ExpChar])==2:\n",
    "                TwoFeature_pairs.add(\n",
    "                    (k[0], k[1])\n",
    "                )\n",
    "\n",
    "print(f'''\n",
    "minimal_pairs: {minimal_pairs}\n",
    "TwoFeature_pairs: {TwoFeature_pairs}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "be68bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_sorted.iterrows():\n",
    "    if (row['ASR Ans'], row['Exp Ans']) in minimal_pairs: \n",
    "        df_sorted.loc[index, 'LD score']=row['LD score']-.5\n",
    "    if (row['ASR Ans'], row['Exp Ans']) in TwoFeature_pairs: \n",
    "        df_sorted.loc[index, 'LD score']=row['LD score']-.25\n",
    "    else: \n",
    "        continue\n",
    " \n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "281587d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASR Ans</th>\n",
       "      <th>Exp Ans</th>\n",
       "      <th>LD score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beðo</td>\n",
       "      <td>deðo</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keðo</td>\n",
       "      <td>deðo</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>peðo</td>\n",
       "      <td>deðo</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deɾo</td>\n",
       "      <td>deðo</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teto</td>\n",
       "      <td>deðo</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bweno</td>\n",
       "      <td>deðo</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASR Ans Exp Ans  LD score\n",
       "2     beðo    deðo      0.75\n",
       "3     keðo    deðo      0.75\n",
       "5     peðo    deðo      0.50\n",
       "9     deɾo    deðo      1.00\n",
       "4     teto    deðo      1.50\n",
       "30   bweno    deðo      2.75"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vowels have 4 features: high/low,front/back, tense/lax (long/short), lip rounding +/-\n",
    "\n",
    "# 1. check all consonants for mistakes \n",
    "# 2.  try to understand current LD function, or find another one that will allow you to understand what it's doing.  \n",
    "# 3.  do a feature set for vowels\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
